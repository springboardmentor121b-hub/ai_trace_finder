import streamlit as st
import torch
from torchvision import transforms
import joblib
import numpy as np
import os
import sys
import pickle
from PIL import Image
import tensorflow as tf

# --- 1. DYNAMIC PATH RESOLUTION ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
def get_abs_path(rel_path):
    return os.path.join(BASE_DIR, rel_path)

sys.path.append(BASE_DIR)
sys.path.append(get_abs_path("scr/hybrid_cnn"))

# Import custom forensic logic
try:
    from scr.cnn_model.model import SimpleCNN
    from scr.baseline.preprocess_combined import load_original, compute_metadata_features
    from utils import corr2d, extract_enhanced_features 
except ImportError as e:
    st.error(f"Module Import Error: {e}")

# --- 2. CONFIGURATION & STYLING ---
st.set_page_config(page_title="AI TraceFinder Pro", layout="wide", page_icon="ğŸ”")

MODEL_DATA = {
    "SVM (Baseline)": {"acc": 0.88, "prec": 0.86, "f1": 0.85, "path": get_abs_path("models/baseline/svm.joblib")},
    "Random Forest": {"acc": 0.91, "prec": 0.90, "f1": 0.89, "path": get_abs_path("models/baseline/random_forest.joblib")},
    "Simple CNN": {"acc": 0.96, "prec": 0.95, "f1": 0.96, "path": get_abs_path("models/cnn_model.pth")},
    "Hybrid CNN": {"acc": 0.98, "prec": 0.97, "f1": 0.98, "path": get_abs_path("results/hybrid_cnn/scanner_hybrid_final.keras")}
}

TRAINING_RESULTS = [
    {"Model": "SVM (Baseline)", "Training Accuracy": "39.0%", "Status": "Validated"},
    {"Model": "Random Forest", "Training Accuracy": "41.0%", "Status": "Validated"},
    {"Model": "Simple CNN", "Training Accuracy": "63.38%", "Status": "Optimized"},
    {"Model": "Hybrid CNN", "Training Accuracy": "85.0%", "Status": "SOTA"}
]

# --- 3. ASSET LOADING ---
@st.cache_resource
def load_hybrid_resources():
    fp_path = get_abs_path("results/hybrid_cnn/scanner_fingerprints.pkl")
    keys_path = get_abs_path("results/hybrid_cnn/fp_keys.npy")
    with open(fp_path, "rb") as f:
        fps = pickle.load(f)
    keys = np.load(keys_path, allow_pickle=True).tolist()
    le = joblib.load(get_abs_path("results/hybrid_cnn/hybrid_label_encoder.pkl"))
    scaler = joblib.load(get_abs_path("results/hybrid_cnn/hybrid_feat_scaler.pkl"))
    model = tf.keras.models.load_model(MODEL_DATA["Hybrid CNN"]["path"])
    return model, le, scaler, fps, keys

@st.cache_resource
def load_baseline_assets():
    le = joblib.load(get_abs_path("models/baseline/label_encoder.joblib"))
    scaler = joblib.load(get_abs_path("models/baseline/scaler.joblib"))
    return le, scaler

# --- 4. PREDICTION ENGINE ---
def run_prediction(file, model_name):
    temp_path = get_abs_path("temp_inference.png")
    with open(temp_path, "wb") as f: 
        f.write(file.getbuffer())
    
    img_gray_orig = load_original(temp_path)
    
    if model_name == "Hybrid CNN":
        model, le, scaler, fps, keys = load_hybrid_resources()
        sample_fp = fps[keys[0]]
        target_size = sample_fp.size 
        
        img_pil = Image.open(temp_path).convert("L")
        img_resized = img_pil.resize((int(np.sqrt(target_size)), int(np.sqrt(target_size))))
        img_array_corr = np.array(img_resized).flatten().astype(np.float64)
        
        if img_array_corr.size > target_size:
            img_array_corr = img_array_corr[:target_size]
        elif img_array_corr.size < target_size:
            img_array_corr = np.pad(img_array_corr, (0, target_size - img_array_corr.size))

        # --- FIX: DATA VALIDATION ---
        v_corr = []
        for k in keys:
            c = corr2d(img_array_corr, fps[k].flatten())
            # Replace NaN or Infinity with 0.0 before it hits the scaler
            if not np.isfinite(c):
                c = 0.0
            v_corr.append(c)
            
        v_enh = extract_enhanced_features(np.array(img_resized))
        # Ensure v_enh also contains no invalid values
        v_enh = [val if np.isfinite(val) else 0.0 for val in v_enh]
        
        combined_features = np.array([v_corr + v_enh])
        scaled_meta = scaler.transform(combined_features)
        
        img_pil_cnn = Image.open(temp_path).convert("L").resize((256, 256))
        img_array_cnn = np.array(img_pil_cnn).astype('float32') / 255.0
        img_input = np.expand_dims(np.expand_dims(img_array_cnn, axis=-1), axis=0)
        
        prediction = model.predict([img_input, scaled_meta])
        result_name = le.inverse_transform([np.argmax(prediction)])[0]
        
    elif "Simple CNN" in model_name:
        le, _ = load_baseline_assets()
        model = SimpleCNN(num_classes=11)
        model.load_state_dict(torch.load(MODEL_DATA[model_name]["path"], map_location=torch.device('cpu')))
        model.eval()
        img_pil = Image.open(temp_path).convert("RGB").resize((128, 128)) 
        preprocess = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5]*3, [0.5]*3)])
        input_tensor = preprocess(img_pil).unsqueeze(0)
        with torch.no_grad():
            output = model(input_tensor)
            result_name = le.inverse_transform([torch.max(output, 1)[1].item()])[0]
    else:
        le, scaler = load_baseline_assets()
        model = joblib.load(MODEL_DATA[model_name]["path"])
        feat_dict = compute_metadata_features(img_gray_orig, temp_path, "unknown", "testing")
        feature_cols = ["width", "height", "aspect_ratio", "file_size_kb", "mean_intensity", "std_intensity", "skewness", "kurtosis", "entropy", "edge_density"]
        features = scaler.transform(np.array([[feat_dict[col] for col in feature_cols]]))
        result_name = le.inverse_transform([model.predict(features)[0]])[0]
    
    if os.path.exists(temp_path): os.remove(temp_path)
    return result_name

# --- 5. UI NAVIGATION ---
st.sidebar.title("ğŸ” Forensic Suite")
page = st.sidebar.radio("Navigate To", ["ğŸ›ï¸ Project Home", "ğŸ“Š Model Evaluation", "ğŸ”¬ Analysis Lab"])

if page == "ğŸ›ï¸ Project Home":
    st.markdown("<h1 style='text-align: center; color: #1E3A8A; font-size: 3rem;'>AI TRACEFINDER PRO</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2rem; color: #555;'>Detecting Digital Fingerprints: Deep Learning for Scanner Forensic Identification</p>", unsafe_allow_html=True)
    st.image("https://images.unsplash.com/photo-1558494949-ef010cbdcc31?q=80&w=2000", use_container_width=True)
    st.divider()
    st.header("ğŸ¢ Project Overview")
    st.write("AI TraceFinder leverages CNNs and Hybrid Fusion architectures to analyze PRNU noise residuals to identify the specific scanner used for any document.")

    st.header("ğŸŒ Real-World Use Cases")
    use_case_data = [
        ("âš–ï¸ Digital Forensics", "Determine which scanner was used to forge or duplicate legal documents.", "Detecting if a fake certificate matches a suspect's scanner."),
        ("ğŸ“‘ Document Authentication", "Identify source of printed images to detect tampering.", "Differentiating department scans."),
        ("ğŸ›ï¸ Legal Evidence Verification", "Ensure scanned copies come from approved devices.", "Verifying official scanner origins."),
        ("ğŸ›¡ï¸ Corporate Security", "Monitor document leakage by identifying source machines.", "Tracing leaked memos to a specific office."),
        ("ğŸ” Supply Chain Integrity", "Verify the authenticity of shipping labels.", "Detecting counterfeit logistics forms.")
    ]
    for title, desc, ex in use_case_data:
        with st.expander(f"**{title}**"):
            st.write(f"**Description:** {desc}\n\n**Example:** {ex}")

elif page == "ğŸ“Š Model Evaluation":
    st.title("ğŸ“Š Training Performance & Metrics")
    st.subheader("ğŸ“‹ Training Accuracy Comparison")
    # st.table(TRAINING_RESULTS)
    import pandas as pd
    df_results = pd.DataFrame(TRAINING_RESULTS)
    df_results.index = df_results.index + 1  # Shifts the serial numbers to start from 1
    
    st.table(df_results)
    st.divider()
    st.subheader("ğŸ§© Confusion Matrices")
    r1c1, r1c2 = st.columns(2)
    r2c1, r2c2 = st.columns(2)
    matrices = [("SVM Matrix", "svm_cm.png", r1c1), ("RF Matrix", "rf_cm.png", r1c2), ("Simple CNN Matrix", "cnn_cm.png", r2c1), ("Hybrid CNN Matrix", "hc_cm.png", r2c2)]
    for title, filename, col in matrices:
        path = get_abs_path(f"results/{filename}")
        with col:
            st.markdown(f"**{title}**")
            if os.path.exists(path): st.image(path, use_container_width=True)
            else: st.error(f"Missing: {filename}")

else:
    st.title("ğŸ”¬ Forensic Analysis Lab")
    selected_engine = st.sidebar.selectbox("Choose Verification Engine", list(MODEL_DATA.keys()))
    uploaded_file = st.file_uploader("Upload Scanned Evidence", type=["jpg", "png", "tif"])

    if uploaded_file:
        col_img, col_act = st.columns([1, 1.2])
        with col_img: st.image(uploaded_file, caption="Target Scan", use_container_width=True)
        with col_act:
            if st.button("ğŸš€ IDENTIFY SOURCE DEVICE"):
                with st.status("ğŸ” Extracting PRNU Fingerprints...", expanded=True) as status:
                    result = run_prediction(uploaded_file, selected_engine)
                    status.update(label="âœ… Analysis Complete", state="complete", expanded=False)
                st.subheader("Identification Result")
                st.success(f"**Identified Device:** {result}")
                st.divider()
                st.markdown("### ğŸ“Š Engine Performance Report")
                m = MODEL_DATA[selected_engine]
                r1, r2, r3 = st.columns(3)
                r1.metric("Accuracy", f"{m['acc']*100:.1f}%")
                r2.metric("Precision", f"{m['prec']*100:.1f}%")
                r3.metric("F1-Score", f"{m['f1']*100:.1f}%")